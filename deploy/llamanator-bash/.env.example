# Enable/Disable Services

# If you are running Ollama on a remote server, you can skip installing it on the Llamanator server.
# If you don't have a GPU, set `ENABLE_OLLAMACPU` to `true`
# If you are running on MacOS, set this to `false` and manually install Ollama on your MacOS machine.
ENABLE_OLLAMACPU=true
# If you have a GPU, set `ENABLE_OLLAMAGPU` to true and set `ENABLE_OLLAMA_CPU` to false
# If you are running on MacOS, set this to `false` and manually install Ollama on your MacOS machine.
ENABLE_OLLAMAGPU=false
# If you want to automatically download llama2, llama3, mistral, nomic-embed, codellama and phi3 models, set this to true. This will take some time to download.
ENABLE_OLLAMA_BASE_MODELS=true
ENABLE_OPENWEBUI=true
ENABLE_DIALOQBASE=true

# General Variables
## Enter the IP address of your server
SERVER_IP=YOUR-SERVER-IP
## Enter the DNS name of your server. This is highly recommended as Llamanator uses this to generate SSL certificates for secure communication.
## Point YOUR.DOMAIN.NAME and *.YOUR.DOMAIN.NAME to the IP address of your server in your DNS settings.
DOMAIN_NAME=YOUR.DOMAIN.NAME
## If you are running Ollama on this server, use this servers IP address. 
## If you are using Ollama on a remote server, you can enter the IP:PORT or DNSNAME:PORT name of that server. 
OLLAMA_ENDPOINT=http://127.0.0.1:11434

## -----Inferencing Services----- ##
# OLLAMA Variables
OLLAMACPU_COMPOSE_FILE=./services/ollama/source/docker-compose-cpu.yml
OLLAMAGPU_COMPOSE_FILE=./services/ollama/source/docker-compose-gpu.yml 
OLLAMACPU_PORT=11434
OLLAMAGPU_PORT=11434

# Llamanator Chat Services
# Typically no need to change these values
## OpenWebUI Variables
OPENWEBUI_COMPOSE_FILE=./services/open-webui/source/docker-compose-llamanator.yml
OPENWEBUI_PORT=10000

## DialoqBase Variables
DIALOQBASE_COMPOSE_FILE=./services/dialoqbase/source/docker-compose-llamanator.yml
DIALOQBASE_PORT=10010

# Llamanator Variables - DO NOT CHANGE
HAPROXY_COMPOSE_FILE=./services/llamanator/haproxy/docker-compose.yml
HAPROXY_PATH=./services/llamanator/haproxy
CONFIG_TEMPLATE=/haproxy.cfg.template
CONFIG_OUTPUT=/haproxy.cfg
LINKS_TEMPLATE=./templates/llamanator-links.txt.template
LINKS_OUTPUT=./llamanator-links.txt
