# Enable/Disable Services

# If you have a GPU, set `ENABLE_OLLAMAGPU` to true and set `ENABLE_OLLAMA_CPU` to false
# If you are running on MacOS, set this to `false` and manually install Ollama on your MacOS machine.
ENABLE_OLLAMAGPU=false
# If you want to automatically download llama2, llama3, mistral, nomic-embed, codellama and phi3 models, set this to true. This will take some time to download.
ENABLE_OLLAMA_BASE_MODELS=true
ENABLE_OPENWEBUI=true
ENABLE_DIALOQBASE=true

# General Variables
export LLAMANATOR_COMPOSE_GROUP_NAME=highsideai-stack

## Enter the IP address of your server
SERVER_IP=YOUR-SERVER-IP
## Enter the DNS name of your server. This is highly recommended as Llamanator uses this to generate SSL certificates for secure communication.
## Point YOUR.DOMAIN.NAME and *.YOUR.DOMAIN.NAME to the IP address of your server in your DNS settings.
DOMAIN_NAME=YOUR.DOMAIN.NAME
## If you are running Ollama on this server, use this servers IP address. 
## If you are using Ollama on a remote server, you can enter the IP:PORT or DNSNAME:PORT name of that server. 
OLLAMA_ENDPOINT=http://127.0.0.1:11434

## -----Inferencing Services----- ##
# OLLAMA Variables
## Empty this if you do not want ollama to predownload models.
PREDOWNLOAD_OLLAMA_MODELS="llama2 mistral nomic-embed-text codellama llama3 phi3"
export OLLAMA_IMAGE_VERSION=0.1.37
export OLLAMA_ORIGINS=*
export OLLAMA_HOST=0.0.0.0
export OLLAMA_PORT=11434
export OLLAMA_NUM_PARALLEL=1
export OLLAMA_MAX_LOADED_MODELS=1
#export OLLAMA_MAX_VRAM=15
export OLLAMA_COMPOSE_FILE=./services/ollama/source/docker-compose.yml
export OLLAMA_GPU_OVERRIDE_COMPOSE_FILE=./services/ollama/source/docker-compose.override.gpu.yml 

# Llamanator Chat Services
# Typically no need to change these values
## OpenWebUI Variables
OPENWEBUI_COMPOSE_FILE=./services/open-webui/source/docker-compose-llamanator.yml
OPENWEBUI_PORT=10000

## DialoqBase Variables
DIALOQBASE_COMPOSE_FILE=./services/dialoqbase/source/docker-compose-llamanator.yml
DIALOQBASE_PORT=10010

# Llamanator Variables - DO NOT CHANGE
HAPROXY_COMPOSE_FILE=./services/llamanator/haproxy/docker-compose.yml
HAPROXY_PATH=./services/llamanator/haproxy
CONFIG_TEMPLATE=/haproxy.cfg.template
CONFIG_OUTPUT=/haproxy.cfg
LINKS_TEMPLATE=./templates/llamanator-links.txt.template
LINKS_OUTPUT=./llamanator-links.txt
